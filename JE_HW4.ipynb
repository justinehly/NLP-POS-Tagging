{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Justin Ehly\n",
    "#### HW4 - NLP\n",
    "#### Answer explanations and discussion are after the code for each section.\n",
    "\n",
    "\n",
    "---\n",
    "##### Exercise 1\n",
    "1.\tRun one of the part-of-speech (POS) taggers available in Python. \n",
    "- a. Find the longest sentence you can, longer than 10 words, that the POS tagger tags correctly. Show the input and output.\n",
    "- b.\tFind the shortest sentence you can, shorter than 10 words, that the POS tagger fails to tag 100 percent correctly. Show the input and output. Explain your conjecture as to why the tagger might have been less than perfect with this sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exercie 1: response:\n",
      "\n",
      "The long sentence that is correctly POS tagged is Sometimes you have to just give up and win by cheating.\n",
      "And here it is tokenized and tagged: [('Sometimes', 'RB'), ('you', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('just', 'RB'), ('give', 'VB'), ('up', 'RP'), ('and', 'CC'), ('win', 'VB'), ('by', 'IN'), ('cheating', 'VBG'), ('.', '.')]\n",
      "--------------------------------------------------------\n",
      "\n",
      "The short sentence that is incorrectly POS tagged is He saw a saw saw something.\n",
      "And here it is tokenized and tagged: [('He', 'PRP'), ('saw', 'VBD'), ('a', 'DT'), ('saw', 'NN'), ('saw', 'NN'), ('something', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk import pos_tag\n",
    "\n",
    "\n",
    "# generate random sentences\n",
    "sents = ['Today is the day I will finally know what brick tastes like.',\n",
    "'It was the best sandcastle he had ever seen.',\n",
    "'Sometimes you have to just give up and win by cheating.',\n",
    "'Today I bought a raincoat and wore it on a sunny day.',\n",
    "'8% of 25 is the same as 25% of 8 and one of them is much easier to do in your head.',\n",
    "'The waves were crashing on the shore; it was a lovely sight.',\n",
    "'Three generations with six decades of life experience.',\n",
    "'A suit of armor provides excellent sun protection on hot days.',\n",
    "'He put heat on the wound to see what would grow.',\n",
    "'He saw a saw saw something.',\n",
    "'He waited for the stop sign to turn to a go sign.']\n",
    "\n",
    "def tag(data):\n",
    "    pos = []\n",
    "    for sent in data:\n",
    "        text = word_tokenize(sent)\n",
    "        pos.append(pos_tag(text)) \n",
    "    return pos\n",
    "\n",
    "\n",
    "\n",
    "tagged_sentences = tag(sents)\n",
    "#for i,sent in enumerate(tagged_sentences):\n",
    "#    if len(sent)>10:\n",
    "#        print(i, sent)\n",
    "\n",
    "\n",
    "#for i, sent in enumerate(tagged_sentences):\n",
    "#    if len(sent) < 10:\n",
    "#        print(i, sent)\n",
    "    \n",
    "print('Exercie 1: response:')\n",
    "print('\\nThe long sentence that is correctly POS tagged is %s' % sents[2])\n",
    "print('And here it is tokenized and tagged: %s' % tagged_sentences[2])    \n",
    "print('--------------------------------------------------------')\n",
    "print('\\nThe short sentence that is incorrectly POS tagged is %s' % sents[9])\n",
    "print('And here it is tokenized and tagged: %s' % tagged_sentences[9])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Exercise 1 Comment:\n",
    "\n",
    "The tagger might've been less than perfect with the short sentence because it did not have a lot of other adjacent words to compare it to. In this case it tagged the thrid 'saw' as a NN when it is a VB.\n",
    "\n",
    "---\n",
    "\n",
    "##### Exercise 2:\n",
    "\n",
    "2.\tRun a different POS tagger in Python. Process the same two sentences from question 1.\n",
    "- a.\tDoes it produce the same or different output?\n",
    "- b.\tExplain any differences as best you can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long sentence from pos_tag:[('Sometimes', 'RB'), ('you', 'PRP'), ('have', 'VBP'), ('to', 'TO'), ('just', 'RB'), ('give', 'VB'), ('up', 'RP'), ('and', 'CC'), ('win', 'VB'), ('by', 'IN'), ('cheating', 'VBG'), ('.', '.')]\n",
      "long sentence from UnigramTagger:[[('Sometimes', None), ('you', 'PPSS'), ('have', 'HV'), ('to', 'TO'), ('just', 'RB'), ('give', 'VB'), ('up', 'RP'), ('and', 'CC'), ('win', 'VB'), ('by', 'IN'), ('cheating', None), ('.', '.')]]\n",
      "-------------\n",
      "short sentence from pos_tag:[('He', 'PRP'), ('saw', 'VBD'), ('a', 'DT'), ('saw', 'NN'), ('saw', 'NN'), ('something', 'NN'), ('.', '.')]\n",
      "short sentence from UnigramTagger:[[('He', 'PPS'), ('saw', 'VBD'), ('a', 'AT'), ('saw', 'VBD'), ('saw', 'VBD'), ('something', 'PN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import brown\n",
    "from nltk.tag import UnigramTagger\n",
    "tagger = UnigramTagger(brown.tagged_sents(categories='fiction')[:500])\n",
    "\n",
    "def ut_tag(data):\n",
    "    pos = []\n",
    "    #for sent in data:\n",
    "    text = word_tokenize(data)\n",
    "    pos.append(tagger.tag(text)) \n",
    "    return pos\n",
    "\n",
    "long_sent = ut_tag(sents[2])\n",
    "short_sent = ut_tag(sents[9])\n",
    "print(f'long sentence from pos_tag:{tagged_sentences[2]}')\n",
    "print(f'long sentence from UnigramTagger:{long_sent}')\n",
    "print('-------------')\n",
    "print(f'short sentence from pos_tag:{tagged_sentences[9]}')\n",
    "print(f'short sentence from UnigramTagger:{short_sent}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 2 Commentary: \n",
    "- I chose to use the UnigramTagger for the 2nd question and train it using 500 words from the fiction category of the Brown corpus. In the long sentence, there are some differences, but the majority of words appear to be correct. In the shorter sentence we see quite a bit of difference as the UnigramTagger is only able to classify 'saw' as a past tense verb.  The UnigramTagger uses statistics to assign the token the most frequenct use of a word based on the training data it sees. In this case, 'saw' is most frequency tagged in the 500 words of the brown text as VBD. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### Exercise 3:\n",
    "\n",
    "3.\tIn a news article from this weekâ€™s news, find a random sentence of at least 10 words.\n",
    "- a.\tLooking at the Penn tag set, manually POS tag the sentence yourself.\n",
    "- b.\tNow run the same sentences through both taggers that you implemented for questions 1 and 2. Did either of the taggers produce the same results as you had created manually?\n",
    "- c.\tExplain any differences between the two taggers and your manual tagging as much as you can.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "my sentence pos tagging:\n",
      "['(News, NN), (of, IN), (the, RB), (delay, NN), (comes, VB), (after, RB), (discussions, NNS), (with, IN), (supply, JJ), (chain, JJ), (sources, NNS), (suggesting, VB), (that, CC), (Apple, NNP), (is, VB), (not, RB), (in, RB), (a, IN), (hurry, VB), (to, to), (enter, VB), (the, RB), (foldable, JJ), (market, NN), (., .)']\n",
      "---\n",
      "pos_tag:\n",
      "[('News', 'NN'), ('of', 'IN'), ('the', 'DT'), ('delay', 'NN'), ('comes', 'VBZ'), ('after', 'IN'), ('discussions', 'NNS'), ('with', 'IN'), ('supply', 'NN'), ('chain', 'NN'), ('sources', 'NNS'), (',', ','), ('suggesting', 'VBG'), ('that', 'IN'), ('Apple', 'NNP'), ('is', 'VBZ'), ('not', 'RB'), ('in', 'IN'), ('a', 'DT'), ('hurry', 'NN'), ('to', 'TO'), ('enter', 'VB'), ('the', 'DT'), ('foldable', 'JJ'), ('market', 'NN'), ('.', '.')]\n",
      "---\n",
      "UnigramTagger sentence:\n",
      "[('News', None), ('of', 'IN'), ('the', 'AT'), ('delay', None), ('comes', 'VBZ'), ('after', 'IN'), ('discussions', None), ('with', 'IN'), ('supply', None), ('chain', None), ('sources', None), (',', ','), ('suggesting', None), ('that', 'CS'), ('Apple', None), ('is', 'BEZ'), ('not', '*'), ('in', 'IN'), ('a', 'AT'), ('hurry', None), ('to', 'TO'), ('enter', 'VB'), ('the', 'AT'), ('foldable', None), ('market', None), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "my_pos = ['(News, NN), (of, IN), (the, RB), (delay, NN), (comes, VB), (after, RB), (discussions, NNS), (with, IN), (supply, JJ), (chain, JJ), (sources, NNS), (suggesting, VB), (that, CC), (Apple, NNP), (is, VB), (not, RB), (in, RB), (a, IN), (hurry, VB), (to, to), (enter, VB), (the, RB), (foldable, JJ), (market, NN), (., .)']\n",
    "article = 'News of the delay comes after discussions with supply chain sources, suggesting that Apple is not in a hurry to enter the foldable market.'\n",
    "token = word_tokenize(article)\n",
    "print('')\n",
    "print(f'my sentence pos tagging:\\n{my_pos}')\n",
    "print('---')\n",
    "print(f'pos_tag:\\n{pos_tag(token)}')\n",
    "print('---')\n",
    "print(f'UnigramTagger sentence:\\n{tagger.tag(token)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercise 3 commentary:\n",
    "- Neither of the taggers got the same results I did manually. This is in part because I am not familiar with many parts of vocabury even with an honesy attempt to look up each word using google and wordnet. \n",
    "- The taggers use different methodology to tag. The pos_tagger is pre-built based on a lexicon. The UnigramTagger was trained using 500 words from a fictional book in the brown corpus where it identifies each word based on how that word was tagged in it the training data. So between the 3 of \"us,\" that is me and the two automatic taggers, we each have a different methodology of how to assign parts of speech to each word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc76590e1530504174433028253576690c6f5ed15348c7b1c3cd4d3d39be5941"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
